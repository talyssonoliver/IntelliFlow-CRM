# Sprint 0 Sub-Agent Orchestration Prompt for Claude Code

## ğŸ¯ Mission Brief

You are orchestrating Sprint 0 of the **IntelliFlow CRM** project. Your task is to coordinate multiple Claude Code sub-agents executing parallel workstreams to establish the complete AI-enhanced development environment within **4 hours**.

**Execution Model**: Use `claude --dangerously-skip-permissions` for autonomous sub-agent spawning with the `Task` tool for parallel orchestration.

---

## ğŸ“Š Sprint 0 Dependency Graph

```
                    EXC-INIT-001 (Root)
                          â”‚
                    AI-SETUP-001
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚                 â”‚
   AI-SETUP-002     AI-SETUP-003      ENV-001-AI
        â”‚                 â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                          â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚     â”‚           â”‚           â”‚           â”‚
                          â”‚ ENV-002-AI  ENV-003-AI  ENV-009-AI  ENV-012-AI
                          â”‚     â”‚           â”‚           â”‚
                          â”‚ ENV-005-AI  ENV-004-AI  ENV-014-AI
                          â”‚     â”‚           â”‚
                          â”‚ ENV-008-AI  ENV-006-AI  ENV-016-AI
                          â”‚     â”‚           â”‚
                          â”‚ ENV-013-AI  ENV-007-AI
                          â”‚     â”‚           â”‚
                          â”‚ EXC-SEC-001    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                          â”‚                â”‚           â”‚
                          â”‚           ENV-010-AI  ENV-011-AI
                          â”‚                â”‚           â”‚
                          â”‚           ENV-015-AI      â”‚
                          â”‚                â”‚           â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                      ENV-017-AI
                                           â”‚
                                      ENV-018-AI
                                           â”‚
                                    AUTOMATION-001
                                           â”‚
                                    AUTOMATION-002

Independent after ENV-001-AI + ENV-002-AI:
- IFC-160 (Artifact conventions + CI lint)
```

---

## ğŸš€ Sub-Agent Execution Strategy

### Phase 0: Initialisation (Sequential - ~5 min)

```bash
# Execute as main agent
claude code --dangerously-skip-permissions

# Task 1: EXC-INIT-001 - Environment Bootstrap
```

**EXC-INIT-001 Instructions**:
```markdown
## Task: Sprint 0 - Environment Setup with Agent Ecosystem

### Pre-requisites Check
- [ ] Budget approved
- [ ] AI tools access confirmed (Claude Code, Copilot)
- [ ] GitHub Enterprise access

### Deliverables
1. Create `docs/agent/setup-complete-checklist.md`
2. Initialise `artifacts/metrics/automation-metrics.json`
3. Create `artifacts/misc/pipeline-status.yaml`

### Definition of Done
- All automation tests passing
- Metrics dashboard live
- Zero manual interventions

### KPIs
- Setup time <4 hours total
- 80% tasks automated
- Zero manual configuration errors
```

---

### Phase 1: AI Foundation (Sequential - ~15 min)

**AI-SETUP-001 Instructions** (blocks all parallel streams):
```markdown
## Task: Configure Claude Code with Custom Commands and Hooks

### Deliverables
1. `.claude/commands/` directory structure:
   - `setup-monorepo.md` - Turborepo initialisation
   - `generate-schema.md` - Prisma schema generation
   - `create-component.md` - React component scaffolding
   - `run-tests.md` - Test execution wrapper
   - `deploy.md` - Deployment automation

2. `.claude/hooks/` configuration:
   - Pre-commit validation hooks
   - Post-push CI triggers
   - PR review automation

3. `artifacts/misc/github-app-config.json`
4. `artifacts/misc/command-test-results.csv`

### Acceptance Criteria
- 100% commands functional
- Hooks triggering <100ms
- GitHub integration verified via E2E test

### Validation Commands
```bash
# Test all slash commands
claude /setup-monorepo --dry-run
claude /generate-schema --validate

# Verify hook performance
time claude hooks test --iterations=100
```
```

---

### Phase 2: Parallel Streams (Concurrent - ~60 min)

Execute these three streams **simultaneously** using the `Task` tool:

```bash
# Spawn 3 parallel sub-agents
Task("PARALLEL-A", "AI Tools Setup") &
Task("PARALLEL-B", "Environment Foundation") &
Task("PARALLEL-C", "Governance & Standards")
```

---

#### ğŸ”· PARALLEL-A: AI Tools Setup

**Sub-agent prompt**:
```markdown
# PARALLEL-A Sub-Agent: AI Tools Integration

You are responsible for AI tooling setup. Execute sequentially:

## AI-SETUP-002: GitHub Copilot Enterprise Automation Setup

### Context
Dependency: AI-SETUP-001 (completed)
Owner: DevOps Engineer
Sprint: 0

### Pre-requisites
- GitHub Enterprise access
- Copilot licenses allocated

### Tasks
1. Create `docs/shared/copilot-instructions.md`:
   ```markdown
   # IntelliFlow Copilot Instructions
   
   ## Project Context
   - TypeScript monorepo (Turborepo)
   - tRPC + Zod for APIs
   - Prisma + Supabase for data
   - LangChain for AI pipelines
   
   ## Code Style
   - Strict TypeScript (no `any`)
   - TDD approach (tests first)
   - Domain-Driven Design patterns
   - Zod validators for all inputs
   
   ## Architecture Patterns
   - Clean Architecture layers
   - Repository pattern for data access
   - CQRS for complex operations
   - Event-driven async processing
   ```

2. Create `.github/copilot/` directory:
   - `suggestions.yaml` - Custom suggestion rules
   - `exclusions.yaml` - Files to ignore
   - `team-settings.json` - Team configuration

3. Create `artifacts/misc/team-licenses.csv`
4. Create `artifacts/misc/workflow-automation.yaml`

### Validation
```bash
# Benchmark Copilot response time
gh copilot explain "How do I create a tRPC router?" --timing

# Verify team access
gh api /orgs/{org}/copilot/billing/seats | jq '.seats | length'
```

### KPIs
- Copilot response <2s
- 100% team access verified
- Automation workflows active

---

## AI-SETUP-003: External AI Tools Integration (Codex, Jules)

### Context
Dependency: AI-SETUP-001 (completed)
Owner: AI Specialist
Sprint: 0

### Pre-requisites
- API keys configured in vault
- Sandbox environments provisioned

### Tasks
1. Create `tools/integrations/codex/`:
   - `cli-config.yaml` - Codex CLI configuration
   - `prompts/` - Standard prompts directory
   - `test-suite.ts` - Integration tests

2. Create `tools/integrations/jules/`:
   - `connection.yaml` - Jules API connection
   - `workflows/` - Automated workflows
   - `test-suite.ts` - Integration tests

3. Create `artifacts/misc/sandbox-security.json`:
   ```json
   {
     "sandboxes": {
       "codex": {
         "network": "isolated",
         "filesystem": "read-only",
         "memory_limit": "4GB",
         "timeout_seconds": 300
       },
       "jules": {
         "network": "restricted",
         "allowed_hosts": ["api.jules.ai"],
         "filesystem": "isolated"
       }
     },
     "security_scan_passed": true,
     "last_audit": "{{ISO_DATE}}"
   }
   ```

4. Create `artifacts/metrics/response-metrics.csv`

### Validation
```bash
# Test Codex integration
codex --version && codex test --timeout=30

# Test Jules connection
curl -X GET https://api.jules.ai/health -H "Authorization: Bearer $JULES_TOKEN"

# Security scan
trivy fs ./tools/integrations/ --severity HIGH,CRITICAL
```

### KPIs
- External tools integrated successfully
- Sandboxing validated (isolated execution)
- Response time <5s
```

---

#### ğŸ”· PARALLEL-B: Environment Foundation

**Sub-agent prompt**:
```markdown
# PARALLEL-B Sub-Agent: Environment Foundation

You are responsible for core environment setup. Execute tasks respecting dependencies.

## ENV-001-AI: Automated Monorepo Creation (CRITICAL PATH)

### Context
Dependency: AI-SETUP-001 (completed)
Owner: Tech Lead + Claude Code
Sprint: 0

### Tasks
1. Execute monorepo generation via Claude command:
   ```bash
   claude /setup-monorepo --preset=intelliflow-crm
   ```

2. Validate structure:
   ```
   intelliflow-crm/
   â”œâ”€â”€ apps/
   â”‚   â”œâ”€â”€ web/           # Next.js 16.0.10 frontend
   â”‚   â”œâ”€â”€ api/           # tRPC API server
   â”‚   â””â”€â”€ ai-worker/     # LangChain workers
   â”œâ”€â”€ packages/
   â”‚   â”œâ”€â”€ db/            # Prisma + Supabase
   â”‚   â”œâ”€â”€ domain/        # DDD domain models
   â”‚   â”œâ”€â”€ validators/    # Zod schemas
   â”‚   â”œâ”€â”€ ui/            # Shared UI components
   â”‚   â””â”€â”€ tsconfig/      # TypeScript configs
   â”œâ”€â”€ infra/
   â”‚   â”œâ”€â”€ docker/        # Container configs
   â”‚   â”œâ”€â”€ supabase/      # Supabase configs
   â”‚   â””â”€â”€ monitoring/    # Observability
   â”œâ”€â”€ docs/              # Documentation
   â”œâ”€â”€ tools/             # Custom tooling
   â”œâ”€â”€ tests/             # Test suites
   â””â”€â”€ artifacts/         # Generated artifacts
   ```

3. Generate configuration files:
   - `artifacts/misc/turbo.json`
   - `artifacts/misc/pnpm-workspace.yaml`
   - `artifacts/misc/monorepo-validation.json`

### Validation
```bash
# Validate structure
pnpm turbo run build --dry-run

# Test workspace linking
pnpm -r exec -- pwd
```

### KPIs
- Setup <10 minutes
- Zero manual steps
- 100% best practices applied

---

## After ENV-001-AI completes, spawn parallel sub-tasks:

### ENV-002-AI: Automated Development Tools Configuration

### Context
Dependency: ENV-001-AI
Owner: DevOps + Copilot

### Tasks
1. Configure ESLint:
   ```javascript
   // .eslintrc.js
   module.exports = {
     extends: [
       'next/core-web-vitals',
       'plugin:@typescript-eslint/strict',
       'plugin:security/recommended',
     ],
     rules: {
       '@typescript-eslint/no-explicit-any': 'error',
       'security/detect-object-injection': 'warn',
     },
   };
   ```

2. Configure Prettier:
   ```json
   // .prettierrc
   {
     "semi": true,
     "singleQuote": true,
     "trailingComma": "es5",
     "tabWidth": 2,
     "printWidth": 100
   }
   ```

3. Configure Husky:
   ```bash
   npx husky install
   npx husky add .husky/pre-commit "pnpm lint-staged"
   npx husky add .husky/commit-msg "pnpm commitlint --edit $1"
   ```

4. Create `artifacts/misc/commitlint.config.js`
5. Create `artifacts/misc/lint-results.json`

### Validation
```bash
# Test linting
pnpm lint

# Test commit hooks
echo "test" | npx commitlint  # Should fail
echo "feat: test feature" | npx commitlint  # Should pass
```

---

### ENV-003-AI: Docker Environment with Optimized Configuration

### Context
Dependency: ENV-001-AI
Owner: DevOps + Claude Code

### Tasks
1. Generate `artifacts/misc/docker-compose.yml`:
   ```yaml
   version: '3.9'
   services:
     db:
       image: supabase/postgres:15.1.0.117
       environment:
         POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
       volumes:
         - postgres_data:/var/lib/postgresql/data
       healthcheck:
         test: ["CMD-SHELL", "pg_isready -U postgres"]
         interval: 5s
         timeout: 5s
         retries: 5

     redis:
       image: redis:7-alpine
       command: redis-server --appendonly yes
       volumes:
         - redis_data:/data
       healthcheck:
         test: ["CMD", "redis-cli", "ping"]
         interval: 5s

     api:
       build:
         context: .
         dockerfile: infra/docker/Dockerfile.api
       depends_on:
         db:
           condition: service_healthy
         redis:
           condition: service_healthy
       environment:
         DATABASE_URL: ${DATABASE_URL}
         REDIS_URL: ${REDIS_URL}

   volumes:
     postgres_data:
     redis_data:
   ```

2. Create Dockerfiles in `infra/docker/`:
   - `Dockerfile.api`
   - `Dockerfile.web`
   - `Dockerfile.worker`

3. Create `artifacts/metrics/container-metrics.json`
4. Create `artifacts/misc/health-check.yaml`

### Validation
```bash
# Spin up environment
docker-compose up -d

# Verify health
docker-compose ps --format json | jq '.[] | select(.Health != "healthy")'

# Time startup
time docker-compose up -d --wait
```

### KPIs
- Environment up <2 minutes
- AI-optimized resource usage
- Self-healing enabled

---

### ENV-009-AI: Frontend with Generated Components

### Context
Dependency: ENV-001-AI
Owner: Frontend Dev + Claude Code

### Tasks
1. Configure Next.js 16.0.10 in `apps/web/`:
   ```bash
   pnpm create next-app apps/web --typescript --tailwind --eslint --app
   ```

2. Install and configure shadcn/ui:
   ```bash
   cd apps/web
   pnpm dlx shadcn@latest init
   pnpm dlx shadcn@latest add button card input form table
   ```

3. Create UI components in `apps/web/components/ui/`

4. Run Lighthouse and accessibility audit:
   ```bash
   lighthouse http://localhost:3000 --output=json --output-path=artifacts/misc/lighthouse-reports/
   ```

5. Create `artifacts/misc/a11y-audit.json`

### Validation
```bash
# Lighthouse score
pnpm lighthouse --score-threshold=95

# Accessibility audit
pnpm exec axe http://localhost:3000
```

### KPIs
- Lighthouse >95
- AI-generated components working
- Load time <1s

---

### ENV-012-AI: Documentation with Auto-Generation

### Context
Dependency: ENV-001-AI
Owner: Tech Writer + AI Agents

### Tasks
1. Set up Docusaurus:
   ```bash
   npx create-docusaurus@latest docs classic --typescript
   ```

2. Configure LLM-friendly structure per `llm-friendly-docs-guide.md`

3. Create `artifacts/misc/docusaurus.config.js`

4. Generate initial docs:
   - `docs/architecture/` - Architecture documentation
   - `docs/api/` - API reference
   - `docs/guides/` - Developer guides

5. Create `artifacts/coverage/doc-coverage.json`
6. Create `artifacts/misc/readability-scores.csv`

### Validation
```bash
# Build docs
cd docs && pnpm build

# Check coverage
pnpm doc-coverage

# Readability check
pnpm textlint docs/**/*.md
```

### KPIs
- Doc generation <30s
- 100% coverage
- AI readability score >90
```

---

#### ğŸ”· PARALLEL-C: Governance & Standards

**Sub-agent prompt**:
```markdown
# PARALLEL-C Sub-Agent: Governance & Standards

You are responsible for security, governance, and standards.

## EXC-SEC-001: Secrets Management (HashiCorp Vault)

### Context
Dependency: ENV-013-AI (but can start setup early)
Owner: Security Eng + DevOps
Sprint: 0

### Pre-requisites
- Secrets Management tool selected (HashiCorp Vault)
- AI access credentials secured

### Tasks
1. Create `artifacts/misc/vault-config.yaml`:
   ```yaml
   vault:
     address: ${VAULT_ADDR}
     auth:
       method: kubernetes
       path: auth/kubernetes
     secrets:
       paths:
         - path: secret/data/intelliflow/openai
           key: api_key
         - path: secret/data/intelliflow/supabase
           key: service_role_key
         - path: secret/data/intelliflow/redis
           key: password
   ```

2. Create `artifacts/misc/access-policy.json`:
   ```json
   {
     "policies": {
       "api-service": {
         "capabilities": ["read"],
         "paths": [
           "secret/data/intelliflow/openai",
           "secret/data/intelliflow/supabase"
         ]
       },
       "ai-worker": {
         "capabilities": ["read"],
         "paths": [
           "secret/data/intelliflow/openai",
           "secret/data/intelliflow/langchain"
         ]
       }
     },
     "audit": {
       "enabled": true,
       "retention_days": 90
     }
   }
   ```

3. Create `artifacts/logs/secret-retrieval-test.log`

### Validation
```bash
# Verify no secrets in codebase
git secrets --scan

# Test vault retrieval
vault kv get secret/intelliflow/openai

# Audit log check
vault audit list
```

### KPIs
- Zero secrets in code/config files
- 100% programmatic access
- Audit log active

---

## IFC-160: Artifact Path Conventions + CI Lint

### Context
Dependency: ENV-001-AI, ENV-002-AI
Owner: Tech Lead + DevOps
Sprint: 0

### Tasks
1. Create `docs/architecture/repo-layout.md`:
   ```markdown
   # IntelliFlow Repository Layout
   
   ## Canonical Artifact Paths
   
   | Category | Path Pattern | Examples |
   |----------|--------------|----------|
   | Metrics | `artifacts/metrics/*.json` | `automation-metrics.json` |
   | Reports | `artifacts/reports/*.{pdf,html}` | `security-assessment.pdf` |
   | Coverage | `artifacts/coverage/*.html` | `coverage-report.html` |
   | Benchmarks | `artifacts/benchmarks/*.{json,csv}` | `query-performance.json` |
   | Logs | `artifacts/logs/*.{log,csv}` | `test-generation-log.json` |
   | Misc | `artifacts/misc/*` | Configuration files |
   
   ## Prohibited Patterns
   - No artifacts in `src/` directories
   - No generated files in `docs/` (except final docs)
   - No secrets in any artifact directory
   ```

2. Create `docs/architecture/artifact-conventions.md`

3. Create `tools/lint/artifact-paths.ts`:
   ```typescript
   import { glob } from 'glob';
   import path from 'path';

   const ALLOWED_PATTERNS = [
     'artifacts/metrics/**/*.json',
     'artifacts/reports/**/*.{pdf,html,xlsx}',
     'artifacts/coverage/**/*.html',
     'artifacts/benchmarks/**/*.{json,csv}',
     'artifacts/logs/**/*.{log,csv,json}',
     'artifacts/misc/**/*',
     'docs/**/*.md',
     '.claude/**/*',
     '.github/**/*',
   ];

   const PROHIBITED_PATTERNS = [
     'src/**/*.{json,csv,log}',
     '**/*.secret*',
     '**/*.key',
   ];

   async function lintArtifacts(): Promise<void> {
     const violations: string[] = [];
     
     // Check for prohibited patterns
     for (const pattern of PROHIBITED_PATTERNS) {
       const matches = await glob(pattern);
       violations.push(...matches);
     }
     
     if (violations.length > 0) {
       console.error('Artifact path violations found:');
       violations.forEach(v => console.error(`  - ${v}`));
       process.exit(1);
     }
     
     console.log('âœ“ All artifact paths valid');
   }

   lintArtifacts();
   ```

4. Create `.github/workflows/artifact-lint.yml`:
   ```yaml
   name: Artifact Path Lint
   
   on:
     pull_request:
       paths:
         - 'artifacts/**'
         - 'docs/**'
         - 'src/**'
   
   jobs:
     lint:
       runs-on: ubuntu-latest
       steps:
         - uses: actions/checkout@v4
         - uses: pnpm/action-setup@v2
         - uses: actions/setup-node@v4
           with:
             node-version: 20
             cache: 'pnpm'
         - run: pnpm install
         - run: pnpm tsx tools/lint/artifact-paths.ts
   ```

5. Create `scripts/migration/artifact-move-map.csv`:
   ```csv
   source_path,destination_path,status,notes
   old/path/metrics.json,artifacts/metrics/metrics.json,pending,Migration required
   ```

### Validation
```bash
# Run lint locally
pnpm tsx tools/lint/artifact-paths.ts

# Test CI workflow
act -j lint -W .github/workflows/artifact-lint.yml
```

### KPIs
- Zero artifact path violations on main
- Lint runtime <60s
- 100% new PRs checked
```

---

### Phase 3: Secondary Dependencies (After Phase 2 - ~45 min)

Once Phase 2 streams complete, continue with dependent tasks:

#### From PARALLEL-B continuation:

```markdown
## ENV-004-AI: Supabase Integration (depends on ENV-003-AI)
## ENV-005-AI: CI/CD Pipeline (depends on ENV-002-AI)
## ENV-014-AI: Performance Optimization (depends on ENV-009-AI)
## ENV-016-AI: Privacy Analytics (depends on ENV-009-AI)
```

#### Deep dependency chain:

```markdown
## ENV-006-AI: Prisma Schema (depends on ENV-004-AI)
## ENV-008-AI: Observability (depends on ENV-005-AI)
## ENV-013-AI: Security Implementation (depends on ENV-005-AI, ENV-007-AI, ENV-009-AI)
```

---

### Phase 4: Integration & Validation (Final - ~30 min)

```markdown
## ENV-010-AI: Automated Test Generation (depends on ENV-007-AI, ENV-009-AI)
## ENV-011-AI: LangChain Integration (depends on ENV-007-AI)
## ENV-015-AI: Feature Flags (depends on ENV-007-AI)

## ENV-017-AI: Integration Testing (depends on ENV-001-AI, ENV-003-AI, ENV-005-AI, ENV-010-AI)

## ENV-018-AI: Sprint Planning (depends on ENV-017-AI)

## AUTOMATION-001: AI Agent Coordination (depends on AI-SETUP-001, AI-SETUP-002, ENV-005-AI, ENV-008-AI, ENV-010-AI)

## AUTOMATION-002: AI Performance Dashboard (depends on AUTOMATION-001)
```

---

## ğŸ“‹ Orchestration Commands

### Main Agent Script

```bash
#!/bin/bash
# sprint0-orchestrate.sh

set -euo pipefail

log() {
  echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1"
}

# Phase 0: Bootstrap
log "ğŸš€ Starting Sprint 0 - EXC-INIT-001"
claude --dangerously-skip-permissions "Execute EXC-INIT-001 per instructions"

# Phase 1: AI Foundation
log "ğŸ”§ Configuring AI Foundation - AI-SETUP-001"
claude --dangerously-skip-permissions "Execute AI-SETUP-001 per instructions"

# Phase 2: Parallel Streams
log "âš¡ Spawning parallel sub-agents"

# PARALLEL-A
claude --dangerously-skip-permissions "Execute PARALLEL-A: AI-SETUP-002, AI-SETUP-003" &
PID_A=$!

# PARALLEL-B
claude --dangerously-skip-permissions "Execute PARALLEL-B: ENV-001-AI â†’ ENV-002-AI, ENV-003-AI, ENV-009-AI, ENV-012-AI" &
PID_B=$!

# PARALLEL-C
claude --dangerously-skip-permissions "Execute PARALLEL-C: EXC-SEC-001, IFC-160" &
PID_C=$!

# Wait for parallel completion
wait $PID_A $PID_B $PID_C

log "âœ… Phase 2 complete - all parallel streams finished"

# Phase 3: Continue dependency chain
log "ğŸ”— Executing dependent tasks"
claude --dangerously-skip-permissions "Execute Phase 3 tasks in dependency order"

# Phase 4: Integration
log "ğŸ§ª Running integration validation"
claude --dangerously-skip-permissions "Execute ENV-017-AI integration testing"

# Final: Sprint planning
log "ğŸ“Š Sprint planning and metrics"
claude --dangerously-skip-permissions "Execute ENV-018-AI, AUTOMATION-001, AUTOMATION-002"

log "ğŸ‰ Sprint 0 Complete!"
```

---

## âœ… Success Criteria

| KPI | Target | Validation |
|-----|--------|------------|
| Total setup time | <4 hours | `time ./sprint0-orchestrate.sh` |
| Tasks automated | >80% | Count automated vs manual steps |
| Manual interventions | 0 | Review logs for manual steps |
| CI/CD pipeline | Operational | Green build on main branch |
| Test coverage | >90% | `pnpm coverage` |
| Security scan | A+ rating | `trivy fs . --severity HIGH,CRITICAL` |
| Documentation coverage | 100% | `pnpm doc-coverage` |

---

## ğŸš¨ Risk Mitigations

| Risk | Mitigation |
|------|------------|
| Sub-agent timeout | Set `--timeout=1800` per stream |
| Dependency failure | Implement retry logic with exponential backoff |
| Resource contention | Use Docker resource limits |
| Secret exposure | Vault-only secret access, no env vars |
| CI rate limiting | Use GitHub App token with higher limits |

---

## ğŸ“ Artifact Tracking

All tasks must produce artifacts in canonical paths:

```
artifacts/
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ automation-metrics.json
â”‚   â”œâ”€â”€ response-metrics.csv
â”‚   â””â”€â”€ container-metrics.json
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ compliance-report.pdf
â”œâ”€â”€ coverage/
â”‚   â”œâ”€â”€ coverage-report.html
â”‚   â””â”€â”€ doc-coverage.json
â”œâ”€â”€ benchmarks/
â”‚   â””â”€â”€ schema-performance.json
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ test-generation-log.json
â”‚   â””â”€â”€ secret-retrieval-test.log
â””â”€â”€ misc/
    â”œâ”€â”€ pipeline-status.yaml
    â”œâ”€â”€ turbo.json
    â”œâ”€â”€ pnpm-workspace.yaml
    â”œâ”€â”€ docker-compose.yml
    â”œâ”€â”€ vault-config.yaml
    â””â”€â”€ ...
```

---

## ğŸ¯ Definition of Done

Sprint 0 is complete when:

1. **All 27 Sprint 0 tasks** have status `Done`
2. **All artifacts** exist at canonical paths
3. **CI/CD pipeline** is green on `main`
4. **Metrics dashboard** is live and populated
5. **Security scan** shows zero critical/high vulnerabilities
6. **Documentation** site builds successfully
7. **All sub-agents** have completed without errors

---

*"We're not setting up infrastructure, we're building the foundation for AI-native excellence."*