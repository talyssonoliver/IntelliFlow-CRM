{
  "task_id": "IFC-125",
  "task_name": "Implement guardrails for prompt injection, data leakage, and monitor AI bias",
  "sprint": 11,
  "section": "AI Foundation",
  "owner": "AI Specialist + Security (STOA-Security)",
  "acknowledged_at": "2025-12-29T23:43:00Z",
  "prerequisites_verified": {
    "constitution": {
      "file": ".specify/memory/constitution.md",
      "verified": true,
      "key_requirements": [
        "AI operations target: <2 seconds",
        "LangChain for AI chains with structured outputs",
        "Zod validation for all AI outputs",
        "Security: sanitize all user-generated content"
      ]
    },
    "dependencies": {
      "IFC-005": {
        "status": "DONE",
        "description": "AI scoring chain implemented"
      },
      "IFC-008": {
        "status": "DONE",
        "description": "Data flows mapped"
      }
    },
    "files_read": [
      "apps/ai-worker/src/chains/scoring.chain.ts",
      "docs/planning/adr/ADR-007-data-governance.md"
    ],
    "ai_models_integrated": true
  },
  "implementation_approach": {
    "prompt_sanitization": {
      "file": "apps/api/src/shared/prompt-sanitizer.ts",
      "techniques": [
        "Input validation with Zod",
        "Blacklist dangerous patterns (SQL injection, command injection)",
        "Content length limits",
        "Rate limiting per user"
      ]
    },
    "output_redaction": {
      "techniques": [
        "PII detection and masking",
        "Sensitive field filtering",
        "Content security policies"
      ]
    },
    "bias_detection": {
      "file": "artifacts/metrics/bias-metrics.csv",
      "metrics": [
        "Score distribution by demographic",
        "Prediction fairness across segments",
        "Model drift monitoring"
      ]
    },
    "incident_logging": {
      "integration": "Existing audit logging system",
      "events": [
        "Prompt injection attempts",
        "Data leakage detections",
        "Bias threshold violations"
      ]
    },
    "testing_strategy": "pnpm test with zero errors target"
  },
  "artifacts_to_create": [
    "apps/api/src/shared/prompt-sanitizer.ts",
    "artifacts/metrics/bias-metrics.csv",
    "docs/shared/ai-guardrails-report.md",
    "artifacts/attestations/IFC-125/context_ack.json"
  ]
}
